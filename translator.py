# -*- coding: utf-8 -*-
"""Translator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/134LSUdEGu6ZTd8SkwBgHwLC1r6uXL7YS
"""

pip install googletrans==4.0.0-rc1

pip install PyMuPDF

from IPython import get_ipython
from IPython.display import display
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

!pip install spacy
!python -m spacy download en_core_web_sm

import spacy

nlp = spacy.load("en_core_web_sm")

def keywords_spaCy(text):
  doc = nlp(text)
  target_pos = {"NOUN", "VERB", "ADJ", "ADV"}
  filtered = [token.text for token in doc if token.pos_ in target_pos]
  #print("Original:", text)
  return filtered

keywords_spaCy("This is an example of removing stopwords from a sentence.")

def remove_stopwords(sentence):
  words = word_tokenize(sentence)
  filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]
  #print("Original:", sentence)
  filtered = " ".join(filtered_words)
  no_punct = filtered.translate(str.maketrans('', '', string.punctuation))
  #print("Filtered: ", no_punct)
  return no_punct

remove_stopwords("This is an example of removing stopwords from a sentence.")

def split_up(filtered):
  list = filtered.split(' ')
  while '' in list:
    list.remove('')
  print(list)
  return list

split_up(remove_stopwords("This is an example of removing stopwords from a sentence."))

"""Code to translate the individual words below:"""

from googletrans import Translator

translator = Translator()

def translate(lang, list):
  translated_words = [translator.translate(word, dest=lang).text for word in list]
  for original, translated in zip(list, translated_words):
    print(f"{original:<15} →        {translated}")
  #return translated_words

translate("ta", split_up(remove_stopwords("Place the People rectangles in the circles on the Data Privacy Spheres sheet starting with the people that you consider closest to you in circle 1 and the people least close to you in circle 7. ")))

translate("ta", keywords_spaCy("Place the People rectangles in the circles on the Data Privacy Spheres sheet starting with the people that you consider closest to you in circle 1 and the people least close to you in circle 7. "))

"""Code for extracting text"""

import fitz

from google.colab import files

# Upload the PDF
uploaded = files.upload()

# The uploaded file will be stored in the '/content/' directory.
pdf_path = list(uploaded.keys())[0]  # Get the file name
print(f"PDF file uploaded: {pdf_path}")

def extract(pdf_path):
  text = ""
  with fitz.open(pdf_path) as doc:
        for page_num, page in enumerate(doc):
            text += page.get_text()
  return text

translate("ta", keywords_spaCy(extract("examplePDF.pdf")))

translate("ta", keywords_spaCy(extract("examplePDF.pdf")))

extract("examplePDF.pdf")

import os

pdf_path = os.path.join(os.getcwd(), "examplePDF.pdf")

# Check if the file exists in the current working directory
if os.path.exists(pdf_path):
    print(f"File exists at {pdf_path}")
else:
    print("❌ File does not exist at the current path.")

print(f"Path being used in Python: {pdf_path}")

from google.colab import files

# Upload the PDF
uploaded = files.upload()

# The uploaded file will be stored in the '/content/' directory.
pdf_path = list(uploaded.keys())[0]  # Get the file name
print(f"PDF file uploaded: {pdf_path}")